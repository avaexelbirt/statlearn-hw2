---
title: "SLHW2"
author: "Ava Exelbirt, Sam Reade"
output: html_document
date: "2024-12-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
# Install necessary libraries if not installed
# install.packages(c("ggplot2", "dplyr", "scales", "lubridate"))
# install.packages("caret")
# install.packages("GGally")
# install.packages("tidyverse")
#install.packages("randomForest")
```

```{r libraries}
# Load libraries
library(ggplot2)
library(dplyr)
library(scales)
library(lubridate)
library(tidyverse)
library(GGally)
library(caret)
library(rpart)
library(rpart.plot)
```

# About the Data

### Import Data

```{r data}
#tuesdata <- tidytuesdayR::tt_load('2022-11-01')
#tuesdata <- tidytuesdayR::tt_load(2022, week = 44)
#horror <- tuesdata$horror_movies
```

```{r glimpse}
glimpse(horror)
```

### Data Dictionary

1.  The `id` variable is an integer that serves as a unique identifier for each movie.
2.  The `original_title` variable is a character string representing the movie's original title.
3.  The `title` variable is a character string containing the localized or alternative movie title.
4.  The `original_language` variable is a character field indicating the language in which the movie was originally made.
5.  The `overview` variable is a character field providing a brief description or synopsis of the movie.
6.  The `tagline` variable is a character field capturing the movie's catchphrase or slogan.
7.  The `release_date` variable is a date field that records the date when the movie was first released.
8.  The `poster_path` variable is a character field containing the URL to the movie's poster image.
9.  The `popularity` variable is a numerical value representing the movie's popularity score based on audience interactions.
10. The `vote_count` variable is an integer field that records the total number of audience votes received.
11. The `vote_average` variable is a numerical field that represents the average audience rating on a scale from 0 to 10.
12. The `budget` variable is an integer field capturing the movie's production budget in USD.
13. The `revenue` variable is an integer field indicating the total revenue earned by the movie in USD.
14. The `runtime` variable is an integer field that specifies the duration of the movie in minutes.
15. The `status` variable is a character field that indicates the current status of the movie, such as "Released."
16. The `adult` variable is a boolean that indicates whether the movie is intended for adult audiences.
17. The `backdrop_path` variable is a character field that provides the URL to the backdrop image for the movie.
18. The `genre_names` variable is a character field listing the genres associated with the movie, separated by commas.
19. The `collection` variable is a numerical field containing the unique ID of the collection the movie belongs to, which may be null for movies not part of a collection.
20. The `collection_name` variable is a character field representing the name of the collection, which may also be null if the movie does not belong to one.

### Available Data

The dataset contains detailed information on a wide range of horror movies, about \~35,000 pieces of entertainment, including various features such as title, genre, release date, runtime, popularity, budget, and revenue. Additional details include the movie's runtime, vote count, average vote, genre names, and collection association. Notably, the dataset also contains the poster and backdrop image URLs for each movie, as well as whether the movie is intended for adults. These data points provide a comprehensive view of each movie's performance, reception, and thematic elements, enabling further analysis on trends, movie popularity, and financial success within the horror genre. These features will be used to train a classification model to predict whether each entry is a successful movie or not. The objective is to leverage these data points to build an accurate classification model, focusing on identifying the key predictors that contribute most to the classification process.

### Motivation

As the entertainment industry expands, identifying the success of a movie is critical to content platforms and production companies. Success in the entertainment industry is typically measured by revenue, budget, and audience reception. Predicting whether a movie is likely to be successful or not can help guide investment decisions, optimize content strategies, and improve user recommendations. However, accurately predicting success is a challenge due to the multifaceted nature of what contributes to a movie's success, including budget, genre, release time, and audience engagement factors.

In this context, predicting a movie's success involves analyzing historical data and identifying patterns that correlate with positive outcomes. By doing so, production teams and platforms can better allocate resources, strategize marketing efforts, and predict the potential success of future movies. The motivation behind this project is to build a classification model that can predict whether a movie will be successful based on various features, thus improving decision-making processes in the entertainment industry.

### Goal

The primary goal of this project is to develop a classification model that predicts whether a given movie is successful or not. The project will focus on feature selection, model interpretation, and the comparison of predictor sets to determine the most significant factors contributing to a movie's success. By analyzing a variety of features such as budget, revenue, genre, and popularity, the goal is to build a model that classifies movies as "successful" or "unsuccessful" with high accuracy. This will allow content platforms and production companies to make data-driven decisions and better understand the elements that contribute to the success of a movie.

# Data Preprocessing and Visualization Tools

```{r summ}
summary(horror)
```

## Data Cleanup

### Handling NA Values

We will look at how many NA values are in each column to better understand our data set.

```{r NA-count}
na_counts <- colSums(is.na(horror))

print(na_counts)

na_counts_df <- data.frame(Column = names(na_counts), NA_Count = na_counts)
print(na_counts_df)

```

```{r}
sum(horror$revenue == 0)
sum(horror$budget == 0)
sum(horror$budget != 0 & horror$revenue != 0)
sum(horror$budget == 0 & horror$revenue == 0)

```

For numeric columns, we will fill missing values with the median values of that column. These include id, release_date, popularity, vote_count, vote_average, revenue, and runtime. We will then fill missing character columns with "Unknown." These include original_title, title, original_language, tagline, overview, poster_path, status, adult, and backdrop_path.

```{r NAs}
numeric_cols <- sapply(horror, is.numeric)
horror[numeric_cols] <- lapply(horror[numeric_cols], function(x) {
  ifelse(is.na(x), median(x, na.rm = TRUE), x)
})

## Fill missing character columns with "Unknown"
char_cols <- sapply(horror, is.character)
horror[char_cols] <- lapply(horror[char_cols], function(x) {
  ifelse(is.na(x), "Unknown", x)
})

```

### Drop Columns

We will remove the columns ids and paths as these are not needed for our overall analysis.

```{r drop}
horror <- horror %>%
  select(-c(id, poster_path, backdrop_path, collection, collection_name))
```

### Feature Engineering

As part of feature engineering we need to create our boolean-like columns to logical data types. We will do so for the adult column. If the observation is FALSE, then it will convert to a logical operator of 0. If the observation is TRUE for this column, then it will be converted to 1. We must also convert categorical columns to factors. This includes original_language, status, and genre_names. Finally, we will extract year from release_date because this will help in further analysis.

```{r feature-eng}
horror$adult <- as.logical(horror$adult)

categorical_cols <- c("original_language", "status", "genre_names")
horror[categorical_cols] <- lapply(horror[categorical_cols], as.factor)

horror$release_year <- as.numeric(substr(horror$release_date, 1, 4))
```

### Handling Outliers

We will replace some outliers. Specifically, for runtime we will replace runtime with the 0 if there is a runtime that is defined as an outlier, we will replace it with 0. We will also remove rows with outliers regarding popularity that is defined as popularity above 10000. We will also categorize budget levels. We categorize movies into "Low", "Medium", or "High" budget based on the budget column:

```{r outliers}
runQ1 <- quantile(horror$runtime, 0.25, na.rm = TRUE)
runQ3 <- quantile(horror$runtime, 0.75, na.rm = TRUE)
IQR <- runQ3 - runQ1
lower_bound <- runQ1 - 1.5 * IQR
upper_bound <- runQ3 + 1.5 * IQR
horror$runtime[horror$runtime < lower_bound | horror$runtime > upper_bound] <- 0

#horror$runtime[horror$runtime <= 0 | horror$runtime > 300] <- NA

horror <- horror[!(horror$popularity > 10000), ]

horror$budget_category <- ifelse(horror$budget == 0, "No Budget",
                           ifelse(horror$budget < 1e7, "Low",
                           ifelse(horror$budget < 5e7, "Medium", "High")))
```

### Create Target Variables

We first create a profit variable that is the revenue minus budget of a movie. We then create a success variable: if profit \> 0, movie is considered successful

```{r make-targ}
horror$profit <- horror$revenue - horror$budget
horror$success <- ifelse(horror$profit > 0, "Success", "No Success")

```

### Correlation Analysis

```{r corr}
ggcorr(horror[ , sapply(horror, is.numeric)], label = TRUE)
```

## Visualization Tools

### Distribution of Numeric Features

We will plot the distributions of numeric features, specifically budget, revenue, and runtime.

```{r num-dist}
ggplot(horror, aes(x = budget)) +
  geom_histogram(binwidth = 1e7, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Budget", x = "Budget", y = "Count") +
  theme_minimal()

ggplot(horror, aes(x = revenue)) +
  geom_histogram(binwidth = 1e7, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Revenue", x = "Revenue", y = "Count") +
  theme_minimal()

ggplot(horror, aes(x = runtime)) +
  geom_histogram(binwidth = 10, fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Runtime", x = "Runtime (Minutes)", y = "Count") +
  theme_minimal()
```

```{r}
# For Budget (which has large values)
ggplot(horror, aes(x = budget)) +
  geom_histogram(binwidth = 1e8, fill = "blue", color = "black", alpha = 0.7) +  # Increase binwidth
  labs(title = "Distribution of Budget", x = "Budget", y = "Count") +
  theme_minimal()

# For Revenue (which also has large values)
ggplot(horror, aes(x = revenue)) +
  geom_histogram(binwidth = 1e8, fill = "green", color = "black", alpha = 0.7) +  # Increase binwidth
  labs(title = "Distribution of Revenue", x = "Revenue", y = "Count") +
  theme_minimal()

# For Runtime (which typically has smaller values)
ggplot(horror, aes(x = runtime)) +
  geom_histogram(binwidth = 5, fill = "red", color = "black", alpha = 0.7) +  # Adjust binwidth for runtime
  labs(title = "Distribution of Runtime", x = "Runtime (Minutes)", y = "Count") +
  theme_minimal()

```

Budget and revenue are both right skewed and unimodal. Runtime is also right skewed, but bimodal.

### Distribution of Some Categorical Features

We will plot the distributions of some categorical features, specifically release_year and budget_category.

```{r cat-dist}
ggplot(horror, aes(x = release_year)) +
  geom_bar(fill = "purple", color = "black") +
  labs(title = "Distribution of Movies by Release Year", x = "Release Year", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(horror, aes(x = budget_category, fill = budget_category)) +
  geom_bar() +
  labs(title = "Distribution of Movies by Budget Category", x = "Budget Category", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")

```

Release year is left skewed and unimodal.

### Distribution of Target Variable

We will now look at the distribution of our target variable, show_or_movie.

###CHANGE WITH NEW PREDICTOR

```{r}
sum(horror$success == "Success")
sum(horror$success == "No Success")
```

```{r horrordist}
ggplot(horror, aes(x = success)) + 
  geom_bar(fill = "lightblue", color = "black") + 
  labs(title = "Distribution of Success of a Movie", x = "Success", y = "Count") + 
  theme_minimal()
```

### Variable Relationships

We first examine the relationship between budget and revenue for each horror movie, with points colored by their budget category, helping to identify patterns and outliers in how budget impacts revenue. We can also visualize how the budget has evolved over the years by plotting release_year versus budget. We then examine the relationship between `popularity` and `vote_average` to see if there's a trend in how movies' popularity correlates with their ratings. We also examine the relationship between `budget` and `profit`. Each point represents a movie, and the color differentiates between successful and non-successful movies. The idea is to see if movies with higher budgets tend to generate more profit. Finally we show how the `profit` distribution differs between successful and non-successful movies. This boxplot shows the distribution of `profit` for movies categorized as "Success" or "No Success". The plot helps visualize how profits are distributed across these categories, revealing if successful movies tend to have higher profits.

```{r}
ggplot(horror, aes(x = budget, y = revenue)) +
  geom_point(aes(color = budget_category), alpha = 0.7) +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Budget vs Revenue", x = "Budget", y = "Revenue") +
  theme_minimal() +
  theme(legend.title = element_blank())

ggplot(horror, aes(x = release_year, y = budget)) +
  geom_point(aes(color = budget_category), alpha = 0.7) +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Release Year vs")

ggplot(horror, aes(x = popularity, y = vote_average)) +
  geom_point(aes(color = genre_names), alpha = 0.7) +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Popularity vs Vote Average", x = "Popularity", y = "Vote Average") +
  theme_minimal() +
  theme(legend.position = "none")

ggplot(horror, aes(x = budget, y = profit)) + 
  geom_point(aes(color = success), alpha = 0.6) + 
  scale_x_continuous(labels = scales::comma) + 
  scale_y_continuous(labels = scales::comma) + 
  labs(title = "Budget vs. Profit", x = "Budget", y = "Profit") + 
  theme_minimal() + 
  theme(legend.title = element_blank())

ggplot(horror, aes(x = success, y = profit, fill = success)) + 
  geom_boxplot() + 
  scale_y_continuous(labels = scales::comma) + 
  labs(title = "Profit Distribution by Success", x = "Success", y = "Profit") + 
  theme_minimal() + 
  theme(legend.title = element_blank())

```

```{r}
sum(horror$budget == 0)
sum(horror$budget != 0)
```

## Split the Data

### Train and Test Data

We will split the data into training (60%) and testing (40%) sets. We will then look at the new data by checking the number of rows in training and testing sets and looking at the summary of the training set.

```{r split}
set.seed(123)

in_train <- createDataPartition(horror$budget_category, p = 0.6, list = FALSE)
training <- horror[in_train, ]
testing <- horror[-in_train, ]

nrow(training)
nrow(testing)

summary(training)
```

### Distribution of Target Variable

```{r show-dist}
table(training$success) / length(training$success)
```

4% successful movies,  96% unsuccessful movies: unbalanced dataset

### Training Visuals

```{r}
# Visualizing the distribution of 'budget' in training data
ggplot(training, aes(x = budget)) + 
  geom_density(fill = "lightblue") + 
  labs(title = "Density of Budget", x = "Budget", y = "Density")

# Visualizing the distribution of 'revenue' in training data
ggplot(training, aes(x = revenue)) + 
  geom_density(fill = "lightgreen") + 
  labs(title = "Density of Revenue", x = "Revenue", y = "Density")

# Visualizing 'budget' against 'revenue'
ggplot(training, aes(x = budget, y = revenue)) + 
  geom_point(aes(color = budget_category), alpha = 0.7) + 
  scale_x_continuous(labels = scales::comma) + 
  scale_y_continuous(labels = scales::comma) + 
  labs(title = "Budget vs Revenue", x = "Budget", y = "Revenue") + 
  theme_minimal() + 
  theme(legend.title = element_blank())

# Exploring 'runtime' distribution
ggplot(training, aes(x = runtime)) + 
  geom_density(fill = "lightcoral") + 
  labs(title = "Density of Runtime", x = "Runtime", y = "Density")

# Exploring 'popularity' distribution
ggplot(training, aes(x = popularity)) + 
  geom_density(fill = "lightyellow") + 
  labs(title = "Density of Popularity", x = "Popularity", y = "Density")

# Decomposing runtime by 'budget_category'
ggplot(training, aes(x = runtime, fill = budget_category)) + 
  geom_density(alpha = 0.5) + 
  labs(title = "Runtime by Budget Category", x = "Runtime", y = "Density")

# Visualizing 'vote_average' distribution
ggplot(training, aes(x = vote_average)) + 
  geom_density(fill = "lightblue") + 
  labs(title = "Density of Vote Average", x = "Vote Average", y = "Density")

# Visualizing 'release_year' distribution
ggplot(training, aes(x = release_year)) + 
  geom_bar(fill = "lightgreen") + 
  labs(title = "Release Year Distribution", x = "Release Year", y = "Count")

# Visualizing the distribution of 'success' in training data
ggplot(training, aes(x = success)) + 
  geom_bar(fill = "lightblue", color = "black") + 
  labs(title = "Distribution of Success", x = "Success", y = "Count") + 
  theme_minimal()

```

# Classification with Emphasis on Prediction

## Questions We Aim to Answer:

1.  "How well can we predict a movie's revenue based on its budget, popularity, and release year?" (Regression)
2.  Predicting popularity (Regression)
3.  "Can we predict whether a movie will be profitable?" (QDA and LDA)
4.  "predicting succes categories (hit, average, flop) (QDA and LDA)
5.  Predicting Budget using logistic regression

```{r}
# Create a new data frame without rows where revenue is 0
df_for_class = subset(horror, revenue != 0 & budget != 0)
df_for_class$success = as.factor(df_for_class$success)

head(df_for_class)
dim(df_for_class)
```

## Visualizaing the Relationships

```{r}
library(ggplot2)

# Scatter plots to see the relationships
ggplot(df_for_class, aes(x = revenue, y = budget)) +
  geom_point() + 
  labs(title = "Budget vs Revenue", x = "Revenue", y = "Budget") +
  theme_minimal()

ggplot(df_for_class, aes(x = release_year, y = budget)) +
  geom_point() + 
  labs(title = "Budget vs Release Year", x = "Release Year", y = "Budget") +
  theme_minimal()

ggplot(df_for_class, aes(x = popularity, y = budget)) +
  geom_point() + 
  labs(title = "Budget vs Popularity", x = "Popularity", y = "Budget") +
  theme_minimal()

ggplot(df_for_class, aes(x = popularity, y = revenue)) +
  geom_point() + 
  labs(title = "Revenue vs Popularity", x = "Popularity", y = "Revenue") +
  theme_minimal()

ggplot(df_for_class, aes(x = release_year, y = revenue)) +
  geom_point() + 
  labs(title = "Revenue vs Release Year", x = "Release Year", y = "Revenue") +
  theme_minimal()

ggplot(df_for_class, aes(x = release_year, y = popularity)) +
  geom_point() + 
  labs(title = "Popularity vs Release Year", x = "Popularity", y = "Budget") +
  theme_minimal()

```

## Classifying Success with LDA:

```{r}
library(MASS)
```

### Training the model

```{r}
lda_model = lda(success ~ budget + release_year + runtime + popularity, data = df_for_class)

lda_model

```

### Predicting

```{r}
predictions_LDA = predict(lda_model, newdata = df_for_class)

predicted_classes_LDA = predictions_LDA$class

predicted_probs_LDA = predictions_LDA$posterior

predictions_LDA_counts = table(predicted_classes_LDA)
print(predictions_LDA_counts)

```

### Evaluating the model with confusion matrix and accuracy calculation

```{r}
confusion_matrix_LDA = table(Predicted_LDA = predicted_classes_LDA, Actual = df_for_class$success)
print(confusion_matrix_LDA)

accuracy_LDA <- sum(predicted_classes_LDA == df_for_class$success) / nrow(df_for_class)
print(paste("Accuracy:", round(accuracy_LDA * 100, 2), "%"))

```

## Classifying Succes with QDA

### Training the model

```{r}
qda_model = qda(success ~ budget + release_year + runtime + popularity, data = df_for_class)

qda_model
```

### Predicting

```{r}
predictions_QDA = predict(qda_model, newdata = df_for_class)

predicted_classes_QDA = predictions_QDA$class

predicted_probs_QDA = predictions_QDA$posterior

predictions_QDA_counts = table(predicted_classes_QDA)
print(predictions_QDA_counts)
```

### Evaluating the model with confusion matrix and accuracy calculation:

```{r}
confusion_matrix_QDA = table(Predicted_QDA = predicted_classes_QDA, Actual = df_for_class$success)
print(confusion_matrix_QDA)

accuracy_QDA = sum(predicted_classes_QDA == df_for_class$success) / nrow(df_for_class)
print(paste("Accuracy:", round(accuracy_QDA * 100, 2), "%"))
```

## Classifying Success with Logistic Regression:

Objective is to predict whether a movie is successful using logistic regression based on budget, release year, runtime, and popularity.

### Training the model

```{r}
lg_model <- glm(success ~ budget + release_year + runtime + popularity, 
                     data = df_for_class, 
                     family = binomial)

summary(lg_model)

```

### Predicting:

```{r}
probabilities_lg = predict(lg_model, newdata = df_for_class, type = "response")

predictions_lg = ifelse(probabilities_lg > 0.5, 1, 0)

predictions_lg_counts = table(predictions_lg)
print(predictions_lg_counts)

```

### Evaluating the model

```{r}
#debug this part
confusion_matrix_lg = table(Predicted_lg = predictions_lg, Actual = df_for_class$success)
print(confusion_matrix_lg)

accuracy_lg = sum(predictions_lg == df_for_class$success) / length(predictions_lg)
print(paste("Accuracy: ", accuracy_lg))

```

The confusion matrix shows the distribution of correct and incorrect predictions. The accuracy percentage provides a measure of how well the model predicts movie success.

```{r}
levels(df_for_class$success)

# Check the unique values in the predicted outcomes
unique(predictions_lg)
```

## Classifying Budget into four predicted groups with multinomial logistic regression:

```{r}
if (!require("nnet")) install.packages("nnet")
library(nnet)
```

### Preparing target

```{r}
budget_quartiles <- quantile(df_for_class$budget, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)
budget_quartiles <- unique(budget_quartiles)  # Remove duplicate values

if (length(budget_quartiles) - 1 != 4) {
  stop("Unable to create exactly 4 quartile groups due to duplicate breaks. Please inspect the data.")
}

# Assign budget categories
df_for_class$budget_category <- cut(
  df_for_class$budget, 
  breaks = budget_quartiles, 
  labels = c("Low", "Medium", "High", "Very High"), 
  include.lowest = TRUE
)

table(df_for_class$budget_category)

```

### Fitting the model

```{r}
df_for_class$budget_category <- as.factor(df_for_class$budget_category)

multinom_model <- multinom(budget_category ~ revenue + release_year + popularity, data = df_for_class)
```

### Check the model summary

```{r}
summary(multinom_model)
```

### Predict classifications

```{r}
predicted_categories = predict(multinom_model, newdata = df_for_class)

category_counts = table(predicted_categories)
print(category_counts)

```

### Evaluating model with confusion matrix and calculating accuracy

```{r}

table(Predicted = predicted_categories, Actual = df_for_class$budget_category)

accuracy <- mean(predicted_categories == df_for_class$budget_category)
cat("Accuracy:", accuracy)

```

# Classification with Emphasis on Interpretation

## Classifying Success with LDA

### Train the Model

```{r}
lda_model <- lda(success ~ budget + release_year + runtime + popularity, data = df_for_class)

# View model coefficients and posterior probabilities
print(lda_model)
```

### Predicting

We will first predict success categories and then add the predictions to the dataset.

```{r}
predictions <- predict(lda_model, newdata = df_for_class)

df_for_class$lda_predicted_success <- predictions$class
```

### Evaluating the Model

We will use the confusion matrix and accuracy to evaluate the model.

```{r}
lda_confusion_matrix <- table(Predicted = predictions$class, Actual = df_for_class$success)

lda_accuracy <- sum(predictions$class == df_for_class$success) / nrow(df_for_class)

print(lda_confusion_matrix)
cat("LDA Accuracy: ", round(lda_accuracy * 100, 2), "%\n")
```

### Visualizing Decision Boundaries

```{r}
ggplot(df_for_class, aes(x = budget, y = popularity, color = lda_predicted_success)) +
  geom_point(alpha = 0.6) +
  labs(title = "Decision Boundaries from LDA", x = "Budget", y = "Popularity") +
  theme_minimal()
```

## Classifying Success with Decision Trees

The decision tree structure shows how features like budget and popularity split the data to classify movies. The path from root to leaf highlights the decision rules. This easily identifies the most important features based on the splits.

### Fit the Model

```{r}
tree_model <- rpart(success ~ budget + release_year + runtime + popularity, data = df_for_class, method = "class")
```

### Visualize the Trees

```{r}
if (!require("rpart.plot")) install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(tree_model, type = 3, extra = 101, under = TRUE, fallen.leaves = TRUE)
```

### Predicting

```{r}
tree_predictions <- predict(tree_model, newdata = df_for_class, type = "class")
```

### Evaluating the Model

Use the confusion matrix to evaluate the model.

```{r}
tree_confusion <- table(Predicted = tree_predictions, Actual = df_for_class$success)
accuracy_tree <- sum(tree_predictions == df_for_class$success) / nrow(df_for_class)

cat("Decision Tree Confusion Matrix:\n")
print(tree_confusion)
cat("Decision Tree Accuracy: ", round(accuracy_tree * 100, 2), "%\n")
```

## Classifying Success with Random Forest (with Feature Importance)

### Fit the Model

```{r}
library(randomForest)

rf_model <- randomForest(success ~ budget + release_year + runtime + popularity, data = df_for_class, importance = TRUE)

```

### View Variable Importance

This shows which features contribute most to the model.

```{r}
importance <- importance(rf_model)
varImpPlot(rf_model)
```

### Prediction

```{r}
rf_predictions <- predict(rf_model, newdata = df_for_class)
```

### Evaluating the Model

Use a confusion matrix to evaluate the model.

```{r}
rf_confusion <- table(Predicted = rf_predictions, Actual = df_for_class$success)
accuracy_rf <- sum(rf_predictions == df_for_class$success) / nrow(df_for_class)

cat("Random Forest Confusion Matrix:\n")
print(rf_confusion)
cat("Random Forest Accuracy: ", round(accuracy_rf * 100, 2), "%\n")

```

## Classifying Success with Naive Bayes

The probabilities for each class provide insight into model confidence.

### Train the Model

```{r}
library(e1071)

nb_model <- naiveBayes(success ~ budget + release_year + runtime + popularity, data = df_for_class)

```

### Prediction

```{r}
nb_predictions <- predict(nb_model, newdata = df_for_class)
```

### Evaluating the Model

Use a confusion matrix to evaluate the model.

```{r}
nb_confusion <- table(Predicted = nb_predictions, Actual = df_for_class$success)
accuracy_nb <- sum(nb_predictions == df_for_class$success) / nrow(df_for_class)

cat("Naïve Bayes Confusion Matrix:\n")
print(nb_confusion)
cat("Naïve Bayes Accuracy: ", round(accuracy_nb * 100, 2), "%\n")
```

# Classifying with Gradient Boosting

```{r}
install.packages("xgboost")
library(xgboost)
```

# Defining target and training data

```{r}
#debugg
GB_training = df_for_class[, c("runtime", "popularity", "budget", "revenue")]
GB_target = df_for_class$success

GB_target = as.numeric(factor(GB_target)) - 1  

set.seed(123)  
train_index = createDataPartition(success, p = 0.8, list = FALSE)  
X_train = GB_training[train_index, ]
y_train = GB_target[train_index]
X_test = GB_training[-train_index, ]
y_test = GB_target[-train_index]

# Converting data to DMatrix (optimized format for xgboost)
dtrain = xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest = xgb.DMatrix(data = as.matrix(X_test), label = y_test)
```

```{r}
# Setting hyperparameters 
params = list(
  objective = "binary:logistic",  
  eval_metric = "logloss",  
  max_depth = 6,  
  eta = 0.1,  
  nthread = 2,  
  colsample_bytree = 0.8,  
  subsample = 0.8  
)

# Training xgboost model
xgb_model = xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,  
  watchlist = list(train = dtrain, test = dtest),  
  early_stopping_rounds = 10
)

```

# Evaluating GB model

```{r}
y_pred = predict(xgb_model, dtest)

y_pred_class = ifelse(y_pred > 0.5, 1, 0)

# Calculating accuracy
accuracy = mean(y_pred_class == y_test)
cat("Test Accuracy: ", accuracy, "\n")

```

**Prediction** using Logistic regression answers the question, "Can we predict success?"

**Interpretation** using LDA highlights "Why are some movies predicted as successful or unsuccessful?" by examining variable relationships and decision boCundaries.

# Feature Selection and Comparison of Predictor Sets

## Feature Importance Analysis

### Correlation Analysis for Continuous Variables

We will analyze the correlation between predictors and the target variable, success. We will identify multicollinearity among predictors to avoid redudancy. We will do so by looking at a correlation matrix for numeric predictors.

```{r}
numeric_vars <- df_for_class[, sapply(df_for_class, is.numeric)]
correlation_matrix <- cor(numeric_vars)
library(corrplot)
corrplot(correlation_matrix, method = "circle")

```

Interpretation: (ADD with context)

-   Strong correlations (close to ±1) between a predictor and `success` suggest high relevance.

-   Avoid using highly correlated predictors simultaneously to prevent redundancy.

### Feature Importance from Random Forest

Random Forest provides a direct measure of feature importance.

```{r}
rf_model <- randomForest(success ~ budget + release_year + runtime + popularity, data = df_for_class, importance = TRUE)
varImpPlot(rf_model)
```

Interpretation: (ADD with context)

-   The variable importance plot ranks features based on their contribution to classification accuracy.

-   Features with higher Mean Decrease Accuracy or Mean Decrease Gini should be prioritized.

### Stepwise Selection

We can use stepwise regression to identify the most relevant features for logistic regression.

```{r}
full_model <- glm(success ~ budget + release_year + runtime + popularity, data = df_for_class, family = binomial)
step_model <- stepAIC(full_model, direction = "both")
summary(step_model)
```

Interpretation: (ADD with context)

-   Features retained in the final model are likely to be the most predictive.

## Comparing Predictor Sets

### Base Set of Predictors

We will use all available predictors: budget, release_year, runtime, and popularity.

```{r}
base_model <- glm(success ~ budget + release_year + runtime + popularity, data = df_for_class, family = binomial)
base_probs <- predict(base_model, type = "response")
base_preds <- ifelse(base_probs > 0.5, 1, 0)
base_accuracy <- mean(base_preds == df_for_class$success)
cat("Base Model Accuracy: ", base_accuracy, "\n")

```

### Reduced Set of Predictors

We will now use only the most important predictors identifies through feature selection **(ADD WHEN FOUND ABOVE).**

```{r}
#EXAMPLE BUT CHANGE WHEN FIND PREDICTORS TO USE
reduced_model <- glm(success ~ budget + popularity, data = df_for_class, family = binomial)
reduced_probs <- predict(reduced_model, type = "response")
reduced_preds <- ifelse(reduced_probs > 0.5, 1, 0)
reduced_accuracy <- mean(reduced_preds == df_for_class$success)
cat("Reduced Model Accuracy: ", reduced_accuracy, "\n")

```

### Adding Interaction Terms

We can test whether interaction terms improve model performance.

```{r}
interaction_model <- glm(success ~ budget * popularity + runtime, data = df_for_class, family = binomial)
interaction_probs <- predict(interaction_model, type = "response")
interaction_preds <- ifelse(interaction_probs > 0.5, 1, 0)
interaction_accuracy <- mean(interaction_preds == df_for_class$success)
cat("Interaction Model Accuracy: ", interaction_accuracy, "\n")

```

### Cross-Validation to Compare Models

Use cross-validation to evaluate the generalizability of each predictor set.

```{r}
# Base Model
base_cv <- train(success ~ budget + release_year + runtime + popularity, data = df_for_class, method = "glm", family = binomial, trControl = trainControl(method = "cv", number = 5))
print(base_cv)

# Reduced Model
reduced_cv <- train(success ~ budget + popularity, data = df_for_class, method = "glm", family = binomial, trControl = trainControl(method = "cv", number = 5))
print(reduced_cv)
```

## Visualize Feature Importance

### Effect Plots for Logistic Regression

Visualize the effect of individual predictors on the probability of success.

```{r}
install.packages("effects")
library(effects)
```

```{r}

effect_plot <- allEffects(reduced_model)
plot(effect_plot)
```

### Partial Dependence Plots

Use this for tree based models like Random Forest.

```{r}
install.packages("pdp")
library(pdp)
```

```{r}
# Partial dependence for "budget"
pd_budget <- partial(rf_model, pred.var = "budget")
plotPartial(pd_budget)

```

```{r}
pd_popularity <- partial(rf_model, pred.var = "popularity")
plotPartial(pd_popularity)
```
